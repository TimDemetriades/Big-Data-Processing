{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980bd8e0-e276-4c7d-9ea8-c3c1443e3aee",
   "metadata": {},
   "source": [
    "# HW 8-1 - Tim Demetriades\n",
    "## Music Recommendation 2 - PySpark & ALS\n",
    "4/17/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79aa80-77af-497d-a5d2-299c6cbf61ce",
   "metadata": {},
   "source": [
    "### Part 1 - Create output predictions file using PySpark and ALS\n",
    "\n",
    "Here, we create `als_predictions.csv`, which will hold the userID, itemID, and predicted item rating. It should be 120,000 entries long, and there should be 6 entries for each user.\n",
    "\n",
    "The input files will be:\n",
    "- `trainItem.data` - the training file in the format `userID,itemID,rating`. It 12,403,570 entries long.\n",
    "- `testItem.data` - the testing file in the format `userID,itemID,rating` where rating is 0. It is 120,000 entries long.\n",
    "\n",
    "First we import the need modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825a6ce8-1bc1-4908-ad80-48b43ecabe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator    # for regression evaluation on the output\n",
    "from pyspark.ml.recommendation import ALS    # for alternating least squares algorithm for matrix factorization\n",
    "from pyspark.sql.types import IntegerType    # for changing df column to int data type\n",
    "from pyspark.sql import SparkSession    # main entry point for DataFrame and SQL functionality\n",
    "from os import path   # for deleting predictions folder\n",
    "import pandas as pd   # for data frames\n",
    "import numpy          # for arrays\n",
    "import time           # for timing cells          \n",
    "import shutil         # for deleting predictions folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d706e-327c-48d8-ad7a-a4a4746c31cd",
   "metadata": {},
   "source": [
    "We initialize SparkSession, the entry point to underlying Spark functionality in order to programmatically create Spark RDD, DataFrame and DataSet.\n",
    "\n",
    "SparkSession contains the functionality of SparkContext, SQLContext, and more (starting with Spark 2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abafe0b6-e455-4452-b163-0f362d7b9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Music Recommender').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd1dd1-3ac0-424b-a546-50f66c1531f3",
   "metadata": {},
   "source": [
    "We can use `spark` to get some data on it and get a link to the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3d2f6a-0708-4202-9c7b-c43dae338a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://TIM-GAMINGPC.fios-router.home:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Music Recommender</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23b4ee8a1c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefe1d5-020b-4dbd-a1c0-3a5406f9c3f2",
   "metadata": {},
   "source": [
    "Now we load the training data file into a PySpark data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35d3ed4-d41e-4071-bc82-4082118ed58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+\n",
      "|   _c0|   _c1|_c2|\n",
      "+------+------+---+\n",
      "|199808|248969| 90|\n",
      "|199808|  2663| 90|\n",
      "|199808| 28341| 90|\n",
      "|199808| 42563| 90|\n",
      "|199808| 59092| 90|\n",
      "+------+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df = spark.read.csv(\"trainItem.data\", header = False)\n",
    "training_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0e68f1-0b57-4037-a964-1082c61f3610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12403575"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec56ae3-38e2-411b-abb4-179043e19955",
   "metadata": {},
   "source": [
    "We can rename the column names using the `.withColumnRenamed()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ad7377-a7e6-45d7-a56c-d4acffaad51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.withColumnRenamed('_c0', 'userID').withColumnRenamed('_c1', 'itemID').withColumnRenamed('_c2', 'rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982246b-b417-4da9-8d08-86b77eebaaaa",
   "metadata": {},
   "source": [
    "We can use the `.dtypes` method to see the data type of each column.\n",
    "\n",
    "Then, we can uset the `.withColumn` method to change the data type of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd41b0a-7d97-4de5-a821-00b9ab592ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userID', 'string'), ('itemID', 'string'), ('rating', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.dtypes    # returns all columns names and their datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32001a1-0f75-471c-8b19-75e8967b3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.withColumn('userID', training_df['userID'].cast(IntegerType()))\n",
    "training_df = training_df.withColumn('itemID', training_df['itemID'].cast(IntegerType()))\n",
    "training_df = training_df.withColumn('rating', training_df['rating'].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d10360e-8496-4d64-bdc0-243b3929eb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userID', 'int'), ('itemID', 'int'), ('rating', 'float')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.dtypes    # returns all columns names and their datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac01f7-1e2d-4c25-bebb-705a87755d6d",
   "metadata": {},
   "source": [
    "Now we will configure the Alternating Least Squares (ALS) model. ALS is an algorithm for recommenders that uses matrix factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c9b7a7-3ec6-41b5-b440-9883950a0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    maxIter=20,              # max number of iterations of the model\n",
    "    rank=15,                 # number of latent features\n",
    "    regParam=1.0,            # regularization parameter\n",
    "    userCol=\"userID\",        # user column (ids must be ints)\n",
    "    itemCol=\"itemID\",        # item column (ids must be ints)\n",
    "    ratingCol=\"rating\",      # ratings column\n",
    "    nonnegative = True,      # whether to use nonnegative constraint for least squares\n",
    "    implicitPrefs = False    # whether to use implicit preference\n",
    "    #coldStartStrategy=\"drop\" # drop any rows in the df of predictions that contain NaN values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284acfc-a339-4288-a134-683b9c9e068e",
   "metadata": {},
   "source": [
    "We then fit the ALS model using the training df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8813bf0c-9f1c-40b9-b623-a047402b6179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Time elapsed - 103.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = als.fit(training_df)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f'Done! Time elapsed - {elapsed_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf7666-6eb0-4343-a5e5-0c3025022bc0",
   "metadata": {},
   "source": [
    "We can use the test data to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e5e1744-5cad-465f-8bc6-d15a3c3fdf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---+\n",
      "|   _c0|   _c1|_c2|\n",
      "+------+------+---+\n",
      "|199810|208019|  0|\n",
      "|199810| 74139|  0|\n",
      "|199810|  9903|  0|\n",
      "|199810|242681|  0|\n",
      "|199810| 18515|  0|\n",
      "+------+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_df = spark.read.csv('testItem.data', header=False)\n",
    "testing_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69bd7120-3ade-4dda-8409-38b5183a221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626757a-1f00-440c-9d46-2575737b3431",
   "metadata": {},
   "source": [
    "Like for the training_df we will rename each column and cast them to the desired data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6dd3003-c873-466c-8ad2-c6427bf01583",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = testing_df.withColumnRenamed(\"_c0\", \"userID\").withColumnRenamed(\"_c1\", \"itemID\").withColumnRenamed(\"_c2\", \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47fc91be-8952-4146-b175-82fb715ee448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userID', 'string'), ('itemID', 'string'), ('rating', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a661044-2aaf-4358-a8f0-4e0cb9520a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = testing_df.withColumn(\"userID\", testing_df[\"userID\"].cast(IntegerType()))\n",
    "testing_df = testing_df.withColumn(\"itemID\", testing_df[\"itemID\"].cast(IntegerType()))\n",
    "testing_df = testing_df.withColumn(\"rating\", testing_df[\"rating\"].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf89aef0-0d22-4a03-9150-ecacf30e5a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userID', 'int'), ('itemID', 'int'), ('rating', 'float')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69374231-c854-4ff2-b112-4fa80ef3744d",
   "metadata": {},
   "source": [
    "Now we can make predictions using the testing data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fde432b-fa88-4b65-aaa3-a104de654268",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testing_df)    # add 'predictions' column to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad91c578-181e-4956-86a1-e41dfee695ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.drop('rating')    # remove ratings column (since it's all just 0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc003826-c252-4927-b808-5ce2fe20372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+\n",
      "|userID|itemID|prediction|\n",
      "+------+------+----------+\n",
      "|230073|   463|  74.94046|\n",
      "|230962|   471|  55.97319|\n",
      "|218845|  1088|  32.30332|\n",
      "|209697|  1088|  57.35444|\n",
      "|224445|  2142| 18.731167|\n",
      "+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e315d4d-c281-4720-9b3d-94293129b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88254b-0aa8-43eb-a8ed-d2882cb26a5c",
   "metadata": {},
   "source": [
    "Now that we have the predictions we can save the data frame to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2eddd46-c55b-454e-98e4-34ee1bb98524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if this folder exists already and if so remove it\n",
    "if path.exists('predictions'):\n",
    "    shutil.rmtree('predictions') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1413f78c-3798-4b81-87e0-1e8d12394841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame into a folder called 'predictions' \n",
    "# with a single file (coalesce(1)) (you cannot assign the filename)\n",
    "predictions.coalesce(numPartitions=1).write.csv(\"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1539b-3322-4282-b6b4-51846f32027a",
   "metadata": {},
   "source": [
    "Finally, we save the predictions to a single file with the desired name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f8f1d60-31d0-443a-9e9f-1a676e437838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame to a single csv file \n",
    "predictions.toPandas().to_csv('als_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcaad2-cd20-42ae-b916-e16a975a5a4a",
   "metadata": {},
   "source": [
    "### Part 2 - Use ratings predictions file to generate predictions\n",
    "Here, we use the output file from Part 1 `als_predictions.csv` to create a predictions file that will hold the predictions for each user in the format `userID_trackID,prediction`. Prediction will either be 1 or 0, with 1 meaning that we predict the user will like the song and 0 meaning that we predict the user will not like the song. For each user there are 6 predictions (6 songs) and there will be 3 1-predictions and 3 0-predictions.\n",
    "\n",
    "The way the predictions work is for the 6 songs for each user, we take the ratings predictions from the previous file and sort them from highest to lowest. Then, we assign the top 3 items a 1 and the bottom 3 items a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd5da70f-44da-4829-98c7-2d107dc5949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files\n",
    "ratings_file = 'als_predictions.csv'\n",
    "predictions_file = 'predictions.csv'\n",
    "final_predictions_file = 'final_predictions.csv'\n",
    "\n",
    "f_ratings = open(ratings_file)\n",
    "f_predictions = open(predictions_file, 'w')\n",
    "f_final_predictions = open(final_predictions_file, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc20674e-c544-4b6e-b506-46ee43739e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write header\n",
    "f_final_predictions.write('TrackID,Predictor\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ff794d-c99c-4e29-8295-b051aeb76182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into df\n",
    "column_list = ('userID', 'itemID', 'prediction')\n",
    "ratings_df = pd.read_csv(ratings_file, usecols=column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0dd1fa3-1b0c-4d96-a353-06a427110370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any value in prediction column is NaN then replcae it with 50.0\n",
    "ratings_df['prediction'] = ratings_df['prediction'].fillna(50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54e60fef-3ff8-41da-8e4b-a0ab4d3324af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230073</td>\n",
       "      <td>463</td>\n",
       "      <td>74.940460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230962</td>\n",
       "      <td>471</td>\n",
       "      <td>55.973190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218845</td>\n",
       "      <td>1088</td>\n",
       "      <td>32.303320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209697</td>\n",
       "      <td>1088</td>\n",
       "      <td>57.354440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224445</td>\n",
       "      <td>2142</td>\n",
       "      <td>18.731167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>230215</td>\n",
       "      <td>294724</td>\n",
       "      <td>59.698616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>224603</td>\n",
       "      <td>294724</td>\n",
       "      <td>20.960081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>218132</td>\n",
       "      <td>294724</td>\n",
       "      <td>59.090970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>235806</td>\n",
       "      <td>295019</td>\n",
       "      <td>87.108110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>227496</td>\n",
       "      <td>295097</td>\n",
       "      <td>72.056060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID  itemID  prediction\n",
       "0       230073     463   74.940460\n",
       "1       230962     471   55.973190\n",
       "2       218845    1088   32.303320\n",
       "3       209697    1088   57.354440\n",
       "4       224445    2142   18.731167\n",
       "...        ...     ...         ...\n",
       "119995  230215  294724   59.698616\n",
       "119996  224603  294724   20.960081\n",
       "119997  218132  294724   59.090970\n",
       "119998  235806  295019   87.108110\n",
       "119999  227496  295097   72.056060\n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e3ee0d4-f984-468b-b365-acc5915f514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by userID (asc) and then by prediction (desc)\n",
    "ratings_df.sort_values([\"userID\", \"prediction\"], ascending = (True, False), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76001ab7-4e6b-4cb3-876b-70a954b86df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to remove original index\n",
    "ratings_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0284e10c-e36f-4af6-b718-827cf9c137c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199810</td>\n",
       "      <td>105760</td>\n",
       "      <td>66.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199810</td>\n",
       "      <td>208019</td>\n",
       "      <td>59.157730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199810</td>\n",
       "      <td>18515</td>\n",
       "      <td>59.097150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199810</td>\n",
       "      <td>242681</td>\n",
       "      <td>47.325626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199810</td>\n",
       "      <td>74139</td>\n",
       "      <td>45.075775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199810</td>\n",
       "      <td>9903</td>\n",
       "      <td>39.301430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>199812</td>\n",
       "      <td>223706</td>\n",
       "      <td>96.742250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199812</td>\n",
       "      <td>211361</td>\n",
       "      <td>89.956055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>199812</td>\n",
       "      <td>142408</td>\n",
       "      <td>86.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>199812</td>\n",
       "      <td>130023</td>\n",
       "      <td>85.505325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>199812</td>\n",
       "      <td>29189</td>\n",
       "      <td>68.595410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>199812</td>\n",
       "      <td>276940</td>\n",
       "      <td>22.910778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  itemID  prediction\n",
       "0   199810  105760   66.244900\n",
       "1   199810  208019   59.157730\n",
       "2   199810   18515   59.097150\n",
       "3   199810  242681   47.325626\n",
       "4   199810   74139   45.075775\n",
       "5   199810    9903   39.301430\n",
       "6   199812  223706   96.742250\n",
       "7   199812  211361   89.956055\n",
       "8   199812  142408   86.111800\n",
       "9   199812  130023   85.505325\n",
       "10  199812   29189   68.595410\n",
       "11  199812  276940   22.910778"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f08df83c-0978-435f-8f14-2b3d1514d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv without index column and header row\n",
    "ratings_df.to_csv('predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be37c8dd-e386-4bfb-8857-7b1d14c9aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_predictions.close()    # close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b15adf0b-5f83-49b2-8ed3-e97a3bd6ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_predictions = open(predictions_file)    # now open it for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24a57e10-a341-4a40-ab63-c58e8f15f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some values\n",
    "ratings_array = numpy.zeros(shape=(6))\n",
    "last_user_id = -1\n",
    "track_id_out_vec = [0] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4377e67c-d2d6-48c8-b3ed-757304d20f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Time elapsed - 0.39 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Go through each line of the predictions file\n",
    "for line in f_predictions:\n",
    "    arr_out = line.strip().split(',')    # remove any spaces/new lines and create list \n",
    "    user_id_out = arr_out[0]             # set user\n",
    "    track_id_out = arr_out[1]            # set track\n",
    "    rating = float(arr_out[2])           # set rating\n",
    "    \n",
    "    if user_id_out != last_user_id:             # if new user reached\n",
    "        i = 0                                   # reset i\n",
    "        ratings_array = numpy.zeros(shape=(6))  # reset this array\n",
    "        \n",
    "    ratings_array[i] = rating                   # add rating to ratings array\n",
    "    track_id_out_vec[i] = track_id_out          # add trackID to trackID array\n",
    "        \n",
    "    i = i + 1                    # increment i\n",
    "    last_user_id = user_id_out   # set last_user_id as current userID\n",
    "    \n",
    "    if i == 6:                               # if last entry for current user reached\n",
    "        # Here we set the predictions \n",
    "        predictions = numpy.zeros(shape=(6)) # initialize numpy array for predictions\n",
    "        for index in range(0, 3):            \n",
    "            predictions[index] = 1           # set first 3 values in array to 1 (other 3 are 0)\n",
    "        \n",
    "        # Here we write to the final predictions file for the 6 track predictions for the current user\n",
    "        for ii in range(0, 6):         \n",
    "            out_str = str(user_id_out) + '_' + str(track_id_out_vec[ii]) + ',' + str(int(predictions[ii]))\n",
    "            f_final_predictions.write(out_str + '\\n')\n",
    "\n",
    "        \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f'Done! Time elapsed - {elapsed_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce56b273-c79a-44e0-bc96-26f50d8e2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ratings.close()\n",
    "f_predictions.close()\n",
    "f_final_predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
