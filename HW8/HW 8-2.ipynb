{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150f3102-fab5-4b6a-8219-a393a5538554",
   "metadata": {},
   "source": [
    "# HW 8 - Tim Demetriades\n",
    "## PySpark Part 2\n",
    "4/17/2021\n",
    "1.   For the provided data file \"re_u.data\", fix the \"numIterations=20\" and use different \"rank\" size,  rank=5, 7, 10, 20 and test the MSE values. \n",
    "2.   For the fixed \"rank=20\", and use different numIterations=2, 5,10, 20 and test the MSE values.\n",
    "3.   For the fixed \"rank=20\" and \"numIterations=20\",  take different size of data. i.e.,  2000, 5000, 10000, 20000, 50000, 100000\n",
    "\n",
    "For the above 3 different scenarios, from your observation, how MSE is changed related to the parameters?   That is, which factor, the rank size, or the numIterations size,  or the data size will change the MSE value more significantly? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf67145-53aa-4f91-91a0-cf03d84720d4",
   "metadata": {},
   "source": [
    "First step is to import the needed modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e527d21-ffec-4de7-a759-6e0dcacd0677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, SparkContext, Rating\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52d0f5-6ca3-48a9-8ff6-b132cc478507",
   "metadata": {},
   "source": [
    "We should then initialize SparkContext, the main entry point for Spark functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49e8074-49fc-4bbc-917f-df9092800a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName='HW 8-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddac8f6-b7bf-44b2-846f-de975365f1f7",
   "metadata": {},
   "source": [
    "We can use `sc` to get some data on it and get a link to the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b80f65-0736-4cbc-bc17-68fc57395310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://TIM-GAMINGPC.fios-router.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW 8-2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=HW 8-2>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d4fd8-c111-4028-9d28-ddd8ee33df30",
   "metadata": {},
   "source": [
    "Read `re_u.data` file from local file system (available on all nodes) and return it as an RDD of Strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19848834-822a-4227-a7ff-829eacd6d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = sc.textFile('re_u.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a92daf-dfc0-4f4c-8db0-39741f658588",
   "metadata": {},
   "source": [
    "We can use the `.take()` method to get the first num elements of the RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5317998-e19d-42f4-861d-34290fda4823",
   "metadata": {},
   "source": [
    "Return a new RDD by applying a function to each element of this RDD. Here we are changing the data type for the 3 columns to make the first 2 columns ints and the last column float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00f94ec-73de-47c1-9be4-785e8d5ed5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(data_original.take(10000))\n",
    "ratings = data.map(lambda l: l.split(',')).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff594e9-1df0-48f5-a0ab-e2406aeec9f6",
   "metadata": {},
   "source": [
    "To print the data in the RDD we need to use the `.collect()` method first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7402e662-9e47-49ba-a371-80da6976ae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating(user=196, product=242, rating=3.0)\n"
     ]
    }
   ],
   "source": [
    "ratings_collection = ratings.collect()    # return a list that contains all of the elements in this RDD\n",
    "print(ratings_collection[0])              # print first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de6c12-a4ae-43c4-aeee-9ef6579bf53f",
   "metadata": {},
   "source": [
    "We can use the `.count()` method to return the number of elements in this RDD. This is the number of rows in `re_u.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e88731a-1727-4360-95a1-8a0371bf9eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba76d7b-b69b-482f-ba33-210302554a08",
   "metadata": {},
   "source": [
    "Next, we build the recommendation model using Alternating Least Squares (ALS) algorithm to do matrix factorization.\n",
    "\n",
    "The ratings matrix is approximated as the product of two lower-rank matrices of a given rank (number of features). To solve for these features, ALS is run iteratively with a configurable level of parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69c67b1-71f8-44c6-95ea-122e5bcc9f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank = 10    # number of latent features\n",
    "numIterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6261dae4-7ea3-4277-afd9-7703598854da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe905afe-c9f1-476b-8ce0-422f47074278",
   "metadata": {},
   "source": [
    "Then, we evalutate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b6cdee-5131-4964-a33a-ac55d8ac585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Time elapsed - 28.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_data = ratings.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_predictions = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MSE = rates_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f'Done! Time elapsed - {elapsed_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04fa096e-cea6-4aaa-a4e6-d7e8c9e66df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.05808\n"
     ]
    }
   ],
   "source": [
    "MSE = round(MSE, 5)\n",
    "print('Mean Squared Error = ' + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109573b6-6b22-46a3-bb32-101065371131",
   "metadata": {},
   "source": [
    "### Part 1 - Adjust Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d079eb08-c08c-43d6-a4ee-8f5b9ce3d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 5 Done! Time elapsed - 28.21 for seconds.\n",
      "Mean Squared Error = 0.22746 for Rank 5.\n",
      "Rank 7 Done! Time elapsed - 27.71 for seconds.\n",
      "Mean Squared Error = 0.14346 for Rank 7.\n",
      "Rank 10 Done! Time elapsed - 27.85 for seconds.\n",
      "Mean Squared Error = 0.0623 for Rank 10.\n",
      "Rank 20 Done! Time elapsed - 27.51 for seconds.\n",
      "Mean Squared Error = 0.00625 for Rank 20.\n"
     ]
    }
   ],
   "source": [
    "numIteration = 20\n",
    "\n",
    "for rank in [5, 7, 10, 20]:\n",
    "    model = ALS.train(ratings, rank, numIterations)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    test_data = ratings.map(lambda p: (p[0], p[1]))\n",
    "    predictions = model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_predictions = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MSE = rates_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Rank {rank} Done! Time elapsed - {elapsed_time:.2f} for seconds.')\n",
    "    MSE = round(MSE, 5)\n",
    "    print(f'Mean Squared Error = {str(MSE)} for Rank {rank}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac841b-5c50-4268-88e7-2842bfd06a67",
   "metadata": {},
   "source": [
    "We can see that for the above, **as the rank increases from 5 to 20, the MSE decreases significantly**, starting at **0.227** for rank 5 and decreasing all the way down to **0.006** for rank 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f000aa7-7ebb-46d1-8fe7-ebb1547fa678",
   "metadata": {},
   "source": [
    "### Part 2 - Adjust numIterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ff7dd8-a285-46a1-88ab-5820aa94db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Iterations Done! Time elapsed - 27.61 for seconds.\n",
      "Mean Squared Error = 0.103 for 2 iterations.\n",
      "5 Iterations Done! Time elapsed - 27.23 for seconds.\n",
      "Mean Squared Error = 0.01631 for 5 iterations.\n",
      "10 Iterations Done! Time elapsed - 27.39 for seconds.\n",
      "Mean Squared Error = 0.00638 for 10 iterations.\n"
     ]
    }
   ],
   "source": [
    "rank = 20\n",
    "\n",
    "for numIterations in [2, 5, 10]:    # we did 20 interations for rank 20 above\n",
    "    model = ALS.train(ratings, rank, numIterations)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    test_data = ratings.map(lambda p: (p[0], p[1]))\n",
    "    predictions = model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_predictions = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MSE = rates_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'{numIterations} Iterations Done! Time elapsed - {elapsed_time:.2f} for seconds.')\n",
    "    MSE = round(MSE, 5)\n",
    "    print(f'Mean Squared Error = {str(MSE)} for {numIterations} iterations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98522707-bc48-4544-9ef2-50dcddcd63b9",
   "metadata": {},
   "source": [
    "We can see that for the above, **as the number of iterations increases, the MSE decreases significantly**, starting at **0.103** for 2 iterations and decreasing all the way down to **0.006** (from the previous part) for 20 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2e260-9e31-4ba2-b074-030a411a6d2c",
   "metadata": {},
   "source": [
    "### Part 3 - Adjust Data Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768d9b07-b8d0-4925-ab5c-b8ce98b69290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 Rows of Data Done! Time elapsed - 26.95 for seconds.\n",
      "Mean Squared Error = 0.0001 for 2000 rows of data.\n",
      "5000 Rows of Data Done! Time elapsed - 27.81 for seconds.\n",
      "Mean Squared Error = 0.00066 for 5000 rows of data.\n",
      "10000 Rows of Data Done! Time elapsed - 26.66 for seconds.\n",
      "Mean Squared Error = 0.00285 for 10000 rows of data.\n",
      "50000 Rows of Data Done! Time elapsed - 27.39 for seconds.\n",
      "Mean Squared Error = 0.15198 for 50000 rows of data.\n",
      "100000 Rows of Data Done! Time elapsed - 27.75 for seconds.\n",
      "Mean Squared Error = 0.29247 for 100000 rows of data.\n"
     ]
    }
   ],
   "source": [
    "numIterations = 20\n",
    "rank = 20\n",
    "\n",
    "for data_size in [2000, 5000, 10000, 50000, 100000]:\n",
    "    data = sc.parallelize(data_original.take(data_size))\n",
    "    ratings = data.map(lambda l: l.split(',')).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))    \n",
    "    \n",
    "    model = ALS.train(ratings, rank, numIterations)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    test_data = ratings.map(lambda p: (p[0], p[1]))\n",
    "    predictions = model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_predictions = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MSE = rates_and_predictions.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'{data_size} Rows of Data Done! Time elapsed - {elapsed_time:.2f} for seconds.')\n",
    "    MSE = round(MSE, 5)\n",
    "    print(f'Mean Squared Error = {str(MSE)} for {data_size} rows of data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe1f4a-ce03-436e-91e3-85651452cd4f",
   "metadata": {},
   "source": [
    "We can see that for the above, **as the amount of data taken increases, the MSE increases** significantly, starting at **0.0001** for 2000 rows of data and increasing all the way up to **0.292** for 100,000 rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf12d6-5b12-418c-9d2f-97a2e155cb18",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "From the results above, we can see that all 3 parameters have an affect on the MSE. Starting with rank, we can see that as you **increase the value of rank** from 5 to 20, the **MSE decreases** by a great amount and therefore the model improves. This makes sense as the model is now using more latent features. \n",
    "\n",
    "Similarly for **number of iterations**, we can see that as this **value goes up the MSE decreases**. This makes sense as well since we are allowing the model to train longer.\n",
    "\n",
    "Finally, we can see that as the **size of the data taken in increases, the MSE decreases**.\n",
    "\n",
    "Of the 3, it appears that **changing the rank produces the biggest affect on MSE**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
